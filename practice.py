# -*- coding: utf-8 -*-
"""rfm_final_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UujfAKSfqUP0Fhz74TvWNiSfzLHfHbgW
"""

#importing labraries

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

data = pd.read_csv("/content/CreditAnalysis_data.csv")
data.head()

data.columns

data1 = data.drop(['Unnamed: 0','master_order_id', 'master_order_status'],axis=1)

#data1["created"] = datetime.strptime(data1["created"], '%B-%d-%Y')
data1["created"] = pd.to_datetime(data1["created"]).dt.strftime("%Y-%m-%d") #"%d-%m-%Y"

data1.info()

##data1.drop(['created'],axis=1,inplace=True)

data1.nunique()

data1.mean()

data1.median()

data1.mode()

data1.max()

data1.min()

data1.var()

data1.describe()

data1.isnull().sum()

data1 = data1.dropna(axis=0)

data1.isnull().sum()

data1.nunique()

data1.to_csv(r"D:\360DigitMT\project_2\Credit_data_final.csv")

sns.histplot(x='order_status',data=data1);

sns.histplot(x='prod_names',data=data1);
#plt.hist(data1.prod_names) #skew to the right positive skewed

cols=2
rows=3
num_cols=data1.select_dtypes(exclude='object').columns

fig = plt.figure(figsize=(cols*5,rows*5))

for i, col in enumerate(num_cols):
    ax = fig.add_subplot(rows,cols,i+1)
    sns.histplot(x=data1[col], ax=ax)
    
fig.tight_layout()
plt.show()

# Scatter plot between the variables along with histograms
import seaborn as sns
sns.pairplot(data1)

data1.corr()

sns.histplot(x='ordereditem_quantity',data=data1, kde=True); #really small values so cant so it

sns.kdeplot(x='order_id',data=data1,hue='order_status')
#KDE the 'kernel density estimate' plot creates a smooth version of a histogram by normalizing all point to appear unnder 
#one curve
#it is best when comparing a variables distribution between groups of another variable, a concept known as segmented univariate
#distribution.

sns.histplot(x='ordereditem_unit_price_net',data=data1, kde=True); #dke with histogram

sns.rugplot(x='ordereditem_quantity',data=data1,height=0.5,color='darkred')

cols=2
rows=3
num_cols=data1.select_dtypes(exclude='object').columns

fig = plt.figure(figsize=(20,15))

for i, col in enumerate(num_cols):
    ax = fig.add_subplot(rows,cols,i+1)
    sns.boxplot(x=data1[col], ax=ax)
    
fig.tight_layout()
plt.show()

cols=3
rows=3
cat_cols=data1.select_dtypes(include='object').columns

fig = plt.figure(figsize=(16,9))

for i, col in enumerate(cat_cols):
    ax = fig.add_subplot(rows,cols,i+1)
    sns.countplot(x=data1[col], ax=ax)
    plt.xticks(rotation=45,ha='right')
    
fig.tight_layout()
plt.show()

data1.head(15)

#data1.drop(["group"], axis=1, inplace=True)

data1.info()

data1["created"] = pd.to_datetime(data1["created"])
data1.info()
#data1["created"] = data1["created"].dt.strftime('%Y-%m-%d')

#Recency = Latest Date - created (Data), Frequency = count of order_id (s), Monetary = Sum of value for each retailer 
from datetime import datetime

#Set Latest date 2018-04-05 as last created was 2018-04-05. This is to calculate the number of days from recent purchase
Latestdate = "06 April, 2018"
Latest_Date = datetime.strptime(Latestdate, "%d %B, %Y")
#Latest_Date = dt.datetime(2018-4-6)
#print(type(Latest_Date))


#Create RFM Modelling scores for each reatiler
RFMScores = data1.groupby('retailer_names').agg({'created':lambda x: (Latest_Date - x.max()).days,'order_id': lambda x: len(x), 'value': lambda x: x.sum()})

#Convert Invoice Date into type int
RFMScores['created'] = RFMScores['created'].astype(int)

#Rename column names to Recency, Frequency and Monetary#
RFMScores.rename(columns={'created': 'Recency',
                         'order_id': 'Frequency',
                         'value': 'Monetary'}, inplace=True)

RFMScores.reset_index().head()

RFMScores.reset_index().head(25)

#Descriptive Statistics (Recency)
RFMScores.Recency.describe()

#Recency distribution plot
import seaborn as sns
x = RFMScores['Recency']

ax = sns.distplot(x)

#Descriptive Statistics (Frequency)
RFMScores.Frequency.describe()

#Frequency distribution plot, taking observations 
import seaborn as sns
x = RFMScores['Frequency']

ax = sns.distplot(x)

#Descriptive Statistics (Monetary)
RFMScores.Monetary.describe()

#Monateray distribution plot, taking observations which have monetary value less than 10000

x = RFMScores['Monetary']

ax = sns.distplot(x)

#Split into four segments using quantiles
quantiles = RFMScores.quantile(q=[0.25,0.5,0.75])
quantiles = quantiles.to_dict()

quantiles

#Functions to create R, F and M segments
def RScoring(x,p,d):
    if x <= d[p][0.25]:
        return 1
    elif x <= d[p][0.50]:
        return 2
    elif x <= d[p][0.75]: 
        return 3
    else:
        return 4
    
def FnMScoring(x,p,d):
    if x <= d[p][0.25]:
        return 4
    elif x <= d[p][0.50]:
        return 3
    elif x <= d[p][0.75]: 
        return 2
    else:
        return 1

#Calculate Add R, F and M segment value columns in the existing dataset to show R, F and M segment values
RFMScores['R'] = RFMScores['Recency'].apply(RScoring, args=('Recency',quantiles,))
RFMScores['F'] = RFMScores['Frequency'].apply(FnMScoring, args=('Frequency',quantiles,))
RFMScores['M'] = RFMScores['Monetary'].apply(FnMScoring, args=('Monetary',quantiles,))
RFMScores.head()

#Calculate and Add RFMGroup value column showing combined concatenated score of RFM
RFMScores['RFMGroup'] = RFMScores.R.map(str) + RFMScores.F.map(str) + RFMScores.M.map(str)

#Calculate and Add RFMScore value column showing total sum of RFMGroup values
RFMScores['RFMScore'] = RFMScores[['R', 'F', 'M']].sum(axis = 1)
RFMScores.head()

#Assign Loyalty Level to each customer
Loyalty_Level = ['Platinum', 'Gold', 'Silver', 'Bronze']
Score_cuts = pd.qcut(RFMScores.RFMScore, q = 4, labels = Loyalty_Level)
RFMScores['RFM_Loyalty_Level'] = Score_cuts.values
RFMScores.reset_index().head()

#Validate the data for RFMGroup = 111
RFMScores[RFMScores['RFMGroup']=='111'].sort_values('Monetary', ascending=False).reset_index().head(10)

pip install chart_studio

import chart_studio as cs
import plotly.offline as po
import plotly.graph_objs as gobj

#Recency Vs Frequency
#graph = RFMScores.query("Monetary < 50000 and Frequency < 2000")

graph = RFMScores

plot_data = [
    gobj.Scatter(
        x=graph.query("RFM_Loyalty_Level == 'Bronze'")['Recency'],
        y=graph.query("RFM_Loyalty_Level == 'Bronze'")['Frequency'],
        mode='markers',
        name='Bronze',
        marker= dict(size= 7,
            line= dict(width=1),
            color= 'blue',
            opacity= 0.8
           )
    ),
        gobj.Scatter(
        x=graph.query("RFM_Loyalty_Level == 'Silver'")['Recency'],
        y=graph.query("RFM_Loyalty_Level == 'Silver'")['Frequency'],
        mode='markers',
        name='Silver',
        marker= dict(size= 9,
            line= dict(width=1),
            color= 'green',
            opacity= 0.5
           )
    ),
        gobj.Scatter(
        x=graph.query("RFM_Loyalty_Level == 'Gold'")['Recency'],
        y=graph.query("RFM_Loyalty_Level == 'Gold'")['Frequency'],
        mode='markers',
        name='Gold',
        marker= dict(size= 11,
            line= dict(width=1),
            color= 'red',
            opacity= 0.9
           )
    ),
    gobj.Scatter(
        x=graph.query("RFM_Loyalty_Level == 'Platinum'")['Recency'],
        y=graph.query("RFM_Loyalty_Level == 'Platinum'")['Frequency'],
        mode='markers',
        name='Platinum',
        marker= dict(size= 13,
            line= dict(width=1),
            color= 'black',
            opacity= 0.9
           )
    ),
]

plot_layout = gobj.Layout(
        yaxis= {'title': "Frequency"},
        xaxis= {'title': "Recency"},
        title='Segments'
    )
fig = gobj.Figure(data=plot_data, layout=plot_layout)
po.iplot(fig)

#Frequency Vs Monetary
#graph = RFMScores.query("Monetary < 50000 and Frequency < 2000")

graph = RFMScores

plot_data = [
    gobj.Scatter(
        x=graph.query("RFM_Loyalty_Level == 'Bronze'")['Frequency'],
        y=graph.query("RFM_Loyalty_Level == 'Bronze'")['Monetary'],
        mode='markers',
        name='Bronze',
        marker= dict(size= 7,
            line= dict(width=1),
            color= 'blue',
            opacity= 0.8
           )
    ),
        gobj.Scatter(
        x=graph.query("RFM_Loyalty_Level == 'Silver'")['Frequency'],
        y=graph.query("RFM_Loyalty_Level == 'Silver'")['Monetary'],
        mode='markers',
        name='Silver',
        marker= dict(size= 9,
            line= dict(width=1),
            color= 'green',
            opacity= 0.5
           )
    ),
        gobj.Scatter(
        x=graph.query("RFM_Loyalty_Level == 'Gold'")['Frequency'],
        y=graph.query("RFM_Loyalty_Level == 'Gold'")['Monetary'],
        mode='markers',
        name='Gold',
        marker= dict(size= 11,
            line= dict(width=1),
            color= 'red',
            opacity= 0.9
           )
    ),
    gobj.Scatter(
        x=graph.query("RFM_Loyalty_Level == 'Platinum'")['Frequency'],
        y=graph.query("RFM_Loyalty_Level == 'Platinum'")['Monetary'],
        mode='markers',
        name='Platinum',
        marker= dict(size= 13,
            line= dict(width=1),
            color= 'black',
            opacity= 0.9
           )
    ),
]

plot_layout = gobj.Layout(
        yaxis= {'title': "Monetary"},
        xaxis= {'title': "Frequency"},
        title='Segments'
    )
fig = gobj.Figure(data=plot_data, layout=plot_layout)
po.iplot(fig)


#Recency Vs Monetary
#graph = RFMScores.query("Monetary < 50000 and Frequency < 2000")

graph = RFMScores

plot_data = [
    gobj.Scatter(
        x=graph.query("RFM_Loyalty_Level == 'Bronze'")['Recency'],
        y=graph.query("RFM_Loyalty_Level == 'Bronze'")['Monetary'],
        mode='markers',
        name='Bronze',
        marker= dict(size= 7,
            line= dict(width=1),
            color= 'blue',
            opacity= 0.8
           )
    ),
        gobj.Scatter(
        x=graph.query("RFM_Loyalty_Level == 'Silver'")['Recency'],
        y=graph.query("RFM_Loyalty_Level == 'Silver'")['Monetary'],
        mode='markers',
        name='Silver',
        marker= dict(size= 9,
            line= dict(width=1),
            color= 'green',
            opacity= 0.5
           )
    ),
        gobj.Scatter(
        x=graph.query("RFM_Loyalty_Level == 'Gold'")['Recency'],
        y=graph.query("RFM_Loyalty_Level == 'Gold'")['Monetary'],
        mode='markers',
        name='Gold',
        marker= dict(size= 11,
            line= dict(width=1),
            color= 'red',
            opacity= 0.9
           )
    ),
    gobj.Scatter(
        x=graph.query("RFM_Loyalty_Level == 'Platinum'")['Recency'],
        y=graph.query("RFM_Loyalty_Level == 'Platinum'")['Monetary'],
        mode='markers',
        name='Platinum',
        marker= dict(size= 13,
            line= dict(width=1),
            color= 'black',
            opacity= 0.9
           )
    ),
]

plot_layout = gobj.Layout(
        yaxis= {'title': "Monetary"},
        xaxis= {'title': "Recency"},
        title='Segments'
    )
fig = gobj.Figure(data=plot_data, layout=plot_layout)
po.iplot(fig)

#K-Means Clustering

#Handle negative and zero values so as to handle infinite numbers during log transformation
def handle_neg_n_zero(num):
    if num <= 0:
        return 1
    else:
        return num
#Apply handle_neg_n_zero function to Recency and Monetary columns 
RFMScores['Recency'] = [handle_neg_n_zero(x) for x in RFMScores.Recency]
RFMScores['Monetary'] = [handle_neg_n_zero(x) for x in RFMScores.Monetary]

#Perform Log transformation to bring data into normal or near normal distribution
Log_Tfd_Data = RFMScores[['Recency', 'Frequency', 'Monetary']].apply(np.log, axis = 1).round(3)

#Data distribution after data normalization for Recency
Recency_Plot = Log_Tfd_Data['Recency']
ax = sns.distplot(Recency_Plot)

#Data distribution after data normalization for Frequency
Frequency_Plot = Log_Tfd_Data['Frequency']
ax = sns.distplot(Frequency_Plot)

#Data distribution after data normalization for Monetary
Monetary_Plot = Log_Tfd_Data['Monetary']
ax = sns.distplot(Monetary_Plot)

from sklearn.preprocessing import StandardScaler

#Bring the data on same scale
scaleobj = StandardScaler()
Scaled_Data = scaleobj.fit_transform(Log_Tfd_Data)

#Transform it back to dataframe
Scaled_Data = pd.DataFrame(Scaled_Data, index = RFMScores.index, columns = Log_Tfd_Data.columns)

Scaled_Data.describe()

from sklearn.cluster import KMeans


sum_of_sq_dist = []

k = list(range(1,15))
for i in k:
    km = KMeans(n_clusters= i, init= "k-means++", max_iter= 1000)
    km.fit(Scaled_Data)
    sum_of_sq_dist.append(km.inertia_)
    
#Plot the graph for the sum of square distance values and Number of Clusters
sum_of_sq_dist
# Scree plot 
plt.plot(k,sum_of_sq_dist, 'ro-');plt.xlabel("No_of_Clusters");plt.ylabel("total_within_SS")

#Perform K-Mean Clustering or build the K-Means clustering model
KMean_clust = KMeans(n_clusters= 3, init= 'k-means++', max_iter= 1000)
KMean_clust.fit(Scaled_Data)

#Find the clusters for the observation given in the dataset
RFMScores['Cluster'] = KMean_clust.labels_
RFMScores.head()

#Saving Scikitlearn models
import joblib
joblib.dump(KMean_clust, "kmeans_model.pkl")

RFMScores.to_csv("Clustered_Customer_Data.csv")

from matplotlib import pyplot as plt
plt.figure(figsize=(7,7))

##Scatter Plot Frequency Vs Recency
Colors = ["red", "green", "blue"]
RFMScores['Color'] = RFMScores['Cluster'].map(lambda p: Colors[p])
ax = RFMScores.plot(    
    kind="scatter", 
    x="Recency", y="Frequency",
    figsize=(10,8),
    c = RFMScores['Color']
)

RFMScores.head(20)

import pickle

pickle.dump(KMean_clust, open("model.pkl",'wb'))